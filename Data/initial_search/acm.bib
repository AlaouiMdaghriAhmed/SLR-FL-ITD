@article{10.1145/3701724,
author = {Wardana, Aulia Arif and Sukarno, Parman},
title = {Taxonomy and Survey of Collaborative Intrusion Detection System using Federated Learning},
year = {2024},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3701724},
doi = {10.1145/3701724},
abstract = {This review article looks at recent research on Federated Learning (FL) for Collaborative Intrusion Detection Systems (CIDS) to establish a taxonomy and survey. The motivation behind this review comes from the difficulty of detecting coordinated cyberattacks in large-scale distributed networks. Collaborative anomalies are one of the network anomalies that need to be detected through robust collaborative learning methods. FL is promising collaborative learning method in recent research. This review aims to offer insights and lesson learn for creating a taxonomy of collaborative anomaly detection in CIDS using FL as a collaborative learning method. Our findings suggest that a taxonomy is required to map the discussion area, including an algorithm for training the learning model, the dataset, global aggregation model, system architecture, security, and privacy. Our results indicate that FL is a promising approach for collaborative anomaly detection in CIDS, and the proposed taxonomy could be useful for future research in this area. Overall, this review contributes to the growing knowledge of FL for CIDS, providing insights and lessons for researchers and practitioners. This research also concludes significant challenges, opportunities, and future directions in CIDS based on collaborative anomaly detection using FL.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {88},
numpages = {36},
keywords = {Coordinated attack, intrusion detection, federated learning, collaborative anomalies, collaborative learning}
}

@inproceedings{10.1145/3607199.3607204,
author = {Zhang, Liwei and Li, Linghui and Li, Xiaoyong and Cai, Binsi and Gao, Yali and Dou, Ruobin and Chen, Luying},
title = {Efficient Membership Inference Attacks against Federated Learning via Bias Differences},
year = {2023},
isbn = {9798400707650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607199.3607204},
doi = {10.1145/3607199.3607204},
abstract = {Federated learning aims to complete model training without private data sharing, but many privacy risks remain. Recent studies have shown that federated learning is vulnerable to membership inference attacks. The weight as an important parameter in neural networks has been proven effective for membership inference attacks, but it leads to significant overhead. Facing this issue, in this paper, we propose a bias-based method for efficient membership inference attacks against federated learning. Different from the weight that determines the direction of the decision surface, the bias also plays an important role in determining the distance to move along the direction. Moreover, the number of bias is way less than the weight. We consider two types of attacks: local attack and global attack, corresponding to two possible types of insiders: participant and central aggregator. For the local attack, we design a neural network-based inference, which fully learns the vertical bias changes of the member data and non-member data. For the global attack, we design a difference comparison-based inference to determine the data source. Extensive experimental results on four public datasets show that the proposed method achieves state-of-the-art inference accuracy. Moreover, experiments prove the effectiveness of the proposed method to resist some commonly used defenses.},
booktitle = {Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses},
pages = {222–235},
numpages = {14},
keywords = {Federated learning, bias, membership inference attack},
location = {Hong Kong, China},
series = {RAID '23}
}

@inproceedings{10.1145/3664476.3670466,
author = {Mansour Bahar, Atmane Ayoub and Ferrahi, Kamel Soa\"{\i}d and Messai, Mohamed-Lamine and Seba, Hamida and Amrouche, Karima},
title = {FedHE-Graph: Federated Learning with Hybrid Encryption on Graph Neural Networks for Advanced Persistent Threat Detection},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3670466},
doi = {10.1145/3664476.3670466},
abstract = {Intrusion Detection Systems (IDS) play a crucial role in safeguarding systems and networks from different types of attacks. However, IDSes face significant hurdles in detecting Advanced Persistent Threats (APTs), which are sophisticated cyber-attacks characterised by their stealth, duration, and advanced techniques. Recent research has explored the effectiveness of Graph Neural Networks (GNNs) in APT detection, leveraging their ability to analyse intricate-relationships within graph data. However, existing approaches often rely on local models, limiting their adaptability to evolving APT-tactics and raising privacy-concerns. In response to these challenges, this paper proposes integrating Federated-Learning (FL) into the architectures of GNN-based Intrusion Detection Systems. Moreover, our solution includes an enhanced encryption-system of the clients’ weights to safely send them to the server through the system’s network. This solution prevents man-in-the-middle (MitM) attacks from intercepting the weights and reconstructing clients data using reverse engineering. We evaluate our approach on several datasets, demonstrating promising results in reducing false-positive rates compared to state-of-the-art Provenance-based IDSes (PIDS).},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {119},
numpages = {10},
keywords = {Advanced Persistent Threats, Federated Learning, Graph Neural Networks, Hybrid Encryption, Intrusion Detection System, Provenance Graph},
location = {Vienna, Austria},
series = {ARES '24}
}

@inproceedings{10.1145/3534678.3539328,
author = {Li, Junyi and Pei, Jian and Huang, Heng},
title = {Communication-Efficient Robust Federated Learning with Noisy Labels},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539328},
doi = {10.1145/3534678.3539328},
abstract = {Federated learning (FL) is a promising privacy-preserving machine learning paradigm over distributed located data. In FL, the data is kept locally by each user. This protects the user privacy, but also makes the server difficult to verify data quality, especially if the data are correctly labeled. Training with corrupted labels is harmful to the federated learning task; however, little attention has been paid to FL in the case of label noise. In this paper, we focus on this problem and propose a learning-based reweighting approach to mitigate the effect of noisy labels in FL. More precisely, we tuned a weight for each training sample such that the learned model has optimal generalization performance over a validation set. More formally, the process can be formulated as a Federated Bilevel Optimization problem. Bilevel optimization problem is a type of optimization problem with two levels of entangled problems. The non-distributed bilevel problems have witnessed notable progress recently with new efficient algorithms. However, solving bilevel optimization problems under the Federated Learning setting is under-investigated. We identify that the high communication cost in hypergradient evaluation is the major bottleneck. So we proposeComm-FedBiO to solve the general Federated Bilevel Optimization problems; more specifically, we propose two communication-efficient subroutines to estimate the hypergradient. Convergence analysis of the proposed algorithms is also provided. Finally, we apply the proposed algorithms to solve the noisy label problem. Our approach has shown superior performance on several real-world datasets compared to various baselines.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {914–924},
numpages = {11},
keywords = {bilevel optimization, data cleaning, federated learning},
location = {Washington DC, USA},
series = {KDD '22}
}

@article{10.1145/3501813,
author = {Antunes, Rodolfo Stoffel and Andr\'{e} da Costa, Cristiano and K\"{u}derle, Arne and Yari, Imrana Abdullahi and Eskofier, Bj\"{o}rn},
title = {Federated Learning for Healthcare: Systematic Review and Architecture Proposal},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {2157-6904},
url = {https://doi.org/10.1145/3501813},
doi = {10.1145/3501813},
abstract = {The use of machine learning (ML) with electronic health records (EHR) is growing in popularity as a means to extract knowledge that can improve the decision-making process in healthcare. Such methods require training of high-quality learning models based on diverse and comprehensive datasets, which are hard to obtain due to the sensitive nature of medical data from patients. In this context, federated learning (FL) is a methodology that enables the distributed training of machine learning models with remotely hosted datasets without the need to accumulate data and, therefore, compromise it. FL is a promising solution to improve ML-based systems, better aligning them to regulatory requirements, improving trustworthiness and data sovereignty. However, many open questions must be addressed before the use of FL becomes widespread. This article aims at presenting a systematic literature review on current research about FL in the context of EHR data for healthcare applications. Our analysis highlights the main research topics, proposed solutions, case studies, and respective ML methods. Furthermore, the article discusses a general architecture for FL applied to healthcare data based on the main insights obtained from the literature review. The collected literature corpus indicates that there is extensive research on the privacy and confidentiality aspects of training data and model sharing, which is expected given the sensitive nature of medical data. Studies also explore improvements to the aggregation mechanisms required to generate the learning model from distributed contributions and case studies with different types of medical data.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
articleno = {54},
numpages = {23},
keywords = {systematic review, federated learning, Electronic health records}
}

@article{10.1145/3501808,
author = {Jiang, Meng and Jung, Taeho and Karl, Ryan and Zhao, Tong},
title = {Federated Dynamic Graph Neural Networks with Secure Aggregation for Video-based Distributed Surveillance},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {2157-6904},
url = {https://doi.org/10.1145/3501808},
doi = {10.1145/3501808},
abstract = {Distributed surveillance systems have the ability to detect, track, and snapshot objects moving around in a certain space. The systems generate video data from multiple personal devices or street cameras. Intelligent video-analysis models are needed to learn dynamic representation of the objects for detection and tracking. Can we exploit the structural and dynamic information without storing the spatiotemporal video data at a central server that leads to a violation of user privacy? In this work, we introduce Federated Dynamic Graph Neural Network (Feddy), a distributed and secured framework to learn the object representations from graph sequences: (1) It aggregates structural information from nearby objects in the current graph as well as dynamic information from those in the previous graph. It uses a self-supervised loss of predicting the trajectories of objects. (2) It is trained in a federated learning manner. The centrally located server sends the model to user devices. Local models on the respective user devices learn and periodically send their learning to the central server without ever exposing the user’s data to server. (3) Studies showed that the aggregated parameters could be inspected though decrypted when broadcast to clients for model synchronizing, after the server performed a weighted average. We design an appropriate aggregation mechanism of secure aggregation primitives that can protect the security and privacy in federated learning with scalability. Experiments on four video camera datasets as well as simulation demonstrate that Feddy achieves great effectiveness and security.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
articleno = {56},
numpages = {23},
keywords = {distributed surveillance, secure aggregation, federated learning, Graph neural network}
}

@inproceedings{10.1145/3545008.3545062,
author = {Su, Lina and Zhou, Ruiting and Wang, Ne and Fang, Guang and Li, Zongpeng},
title = {An Online Learning Approach for Client Selection in Federated Edge Learning under Budget Constraint},
year = {2023},
isbn = {9781450397339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545008.3545062},
doi = {10.1145/3545008.3545062},
abstract = {Federated learning (FL) has emerged as a new paradigm that enables distributed mobile devices to learn a global model collaboratively. Since mobile devices (a.k.a, clients) exhibit diversity in model training quality, client selection (CS) becomes critical for efficient FL. CS faces the following challenges: First, the client’s availability, the training data volumes, and the network connection status are time-varying and cannot be easily predicted. Second, clients for training and the number of local iterations would seriously affect the model accuracy. Thus, selecting a subset of available clients and controlling local iterations should guarantee model quality. Third, renting clients for model training needs cost. It is necessary to dynamically administrate the use of the long-term budget without knowledge of future inputs. To this end, we propose a federated edge learning (FedL) framework, which can select appropriate clients and control the number of training iterations in real-time. FedL aims to reduce the completion time while reaching the desired model convergence and satisfying the long-term budget for renting clients. FedL consists of two algorithms: i) the online learning algorithm makes CS and iteration decisions according to historic learning results; ii) the online rounding algorithm translates fractional decisions derived by the online learning algorithm into integers to satisfy feasibility constraints. Rigorous mathematical proof reveals that dynamic regret and dynamic fit have sub-linear upper-bounds with time for a given budget. Extensive experiments based on realistic datasets suggest that FedL outperforms multiple state-of-the-art algorithms. In particular, FedL reduces&nbsp;at least 38\% completion time compared with others.},
booktitle = {Proceedings of the 51st International Conference on Parallel Processing},
articleno = {72},
numpages = {11},
keywords = {online learning, federated learning, client selection, budget},
location = {Bordeaux, France},
series = {ICPP '22}
}

@inproceedings{10.1145/3664476.3670874,
author = {Mhiri, Saber and Egio, Alfonso and Compasti\'{e}, Maxime and Cosio, Pablo},
title = {Proxy Re-Encryption for Enhanced Data Security in Healthcare: A Practical Implementation},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3670874},
doi = {10.1145/3664476.3670874},
abstract = {In the rapidly evolving digital healthcare landscape, the imperative for robust, flexible, and scalable data protection solutions has never been more critical. The advent of sophisticated cyber threats, coupled with the increasing complexity of healthcare IT infrastructures, underscores the necessity for advanced security mechanisms that can adapt to a wide range of challenges without compromising the accessibility or integrity of sensitive healthcare data. Within this context, our work introduces the SECANT Privacy Toolkit, a pioneering approach that harnesses the power of Proxy Re-Encryption (PRE) to redefine healthcare data security. We present an implementation prototype that not only serves as a baseline for the quantitative evaluation of healthcare data protection but also exemplifies the SECANT Toolkit’s capability to enhance interoperability across disparate healthcare systems, strengthen authentication mechanisms, and ensure scalability amidst the growing data demands of modern healthcare networks. This prototype underscores our commitment to addressing the multifaceted security needs of the healthcare sector by providing a solution that is both comprehensive and adaptable to the dynamic landscape of digital health information security.By integrating cutting-edge cryptographic technologies, including Attribute-Based Encryption (ABE) and Searchable Encryption (SE), with the flexibility and control offered by PRE, the SECANT Privacy Toolkit stands at the forefront of secure and efficient healthcare data management. This integration facilitates not only the secure exchange of data across decentralized networks but also empowers healthcare providers with tools for fine-grained access control and privacy-preserving data searches, thereby addressing key challenges such as data interoperability, cybersecurity threats, and regulatory compliance.Our exploration reveals the toolkit’s potential to revolutionize the way healthcare data is protected, shared, and accessed, providing a scalable, efficient, and user-friendly platform for healthcare providers, patients, and stakeholders. The SECANT Privacy Toolkit not only aligns with current healthcare data security requirements but also anticipates future challenges, ensuring that it remains a vital asset in the ongoing effort to safeguard sensitive healthcare information. This work contributes significantly toward enhancing the security and privacy of healthcare data, offering a robust framework for interoperability, authentication, and scalability that responds to the evolving needs of the healthcare industry. Through the deployment of our prototype and the subsequent evaluation, we aim to demonstrate the practicality, effectiveness, and transformative potential of the SECANT Privacy Toolkit in advancing healthcare data protection.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {152},
numpages = {11},
keywords = {Advanced Encryption Methods, Cryptographic Key Management, Cryptographic Security, Cybersecurity in Healthcare, Data Privacy in Healthcare, Digital Health Information Security, Encryption Technologies, Healthcare Data Security, Interoperability in Healthcare Systems, Medical Data Protection, Patient Data Confidentiality, Proxy Re-Encryption (PRE), SECANT Platform, Secure Data Delegation, Secure Data Sharing},
location = {Vienna, Austria},
series = {ARES '24}
}

@inproceedings{10.1145/3538969.3543820,
author = {Grammatikakis, Konstantinos-Panagiotis and Koufos, Ioannis and Kolokotronis, Nicholas},
title = {A Collaborative Intelligent Intrusion Response Framework for Smart Electrical Power and Energy Systems},
year = {2022},
isbn = {9781450396707},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3538969.3543820},
doi = {10.1145/3538969.3543820},
abstract = {Smart grid systems build upon existing electrical grid infrastructure by integrating power and information technologies allowing electrical power service providers to optimise their services. The combination of complex networks formed by interconnected heterogeneous devices, and the bidirectional nature of communications between end users and service providers makes security a challenging task. As implicit trust relations formed by smart grid components expand the attack surface considerably, a highly adaptable solution is required to secure these systems. In this paper, the design of an intelligent intrusion response system is explored, which can respond to ongoing multi-stage attacks in an optimal manner with respect to service availability. The smart grid infrastructure’s vulnerabilities are modelled with a graphical network security model allowing the application of probabilistic risk management methods for quantifying threats and their corresponding risks. A game-theoretic approach has been implemented that leverages the security models to efficiently respond to cyber-attacks, whose performance is tightly coupled with the system’s attack detection capabilities. To achieve better results and ensure inter-component privacy a federated learning approach was adopted. Preliminary testing on a simulated home area network with attacks against the Modbus, BACnet, and MQTT protocols, in addition to Mirai and BlackEnergy attacks, was performed to test the viability of this approach. The results illustrated the successful mitigation of attacks but also highlighted the need to implement collaborative mechanisms into the intrusion response part of the model.},
booktitle = {Proceedings of the 17th International Conference on Availability, Reliability and Security},
articleno = {76},
numpages = {10},
keywords = {Cyber-security, attack mitigation, collaborative intrusion detection, graphical security models., power grid},
location = {Vienna, Austria},
series = {ARES '22}
}

@inproceedings{10.1145/3635059.3635096,
author = {Roumpies, Fotios and Kakarountas, Athanasios},
title = {A Review of Homomorphic Encryption and its Contribution to the Sector of Health Services},
year = {2024},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635059.3635096},
doi = {10.1145/3635059.3635096},
abstract = {Homomorphic encryption is a groundbreaking cryptographic method that has made giant contributions to healthcare by addressing the urgent need for steady and privacy-keeping information analysis and sharing. This encryption approach permits information to be processed while nonetheless in its encrypted form, permitting healthcare businesses to perform complex computations on confidential patient information without compromising character privacy or data protection. It paved the way for secure cloud-based facts storage, sharing, and collaborative healthcare research, facilitating advancements in fact-driven selection-making, customized medicinal drugs, and remote affected person tracking. Homomorphic encryption has emerged as a vital enabler of innovation by maintaining the confidentiality of affected personal information while enabling meaningful analysis.},
booktitle = {Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {237–242},
numpages = {6},
keywords = {Healthcare, Homomorphic Encryption, data security, digital libraries, secure data sharing},
location = {Lamia, Greece},
series = {PCI '23}
}

@proceedings{10.1145/3672121,
title = {CNCIT '24: Proceedings of the 2024 3rd International Conference on Networks, Communications and Information Technology},
year = {2024},
isbn = {9798400717048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi'an, China}
}

@proceedings{10.1145/3672200,
title = {ZTA-NextGen '24: Proceedings of the SIGCOMM Workshop on Zero Trust Architecture for Next Generation Communications},
year = {2024},
isbn = {9798400707155},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@proceedings{10.1145/3649403,
title = {WiseML '24: Proceedings of the 2024 ACM Workshop on Wireless Security and Machine Learning},
year = {2024},
isbn = {9798400706028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the ACM Workshop on Wireless Security and Machine Learning (WiseML) 2024. This year's workshop continues its tradition of being a premier forum to bring together members of the ML, privacy, security, wireless communications, and networking communities from around the world. It provides a platform to share the latest research findings in these emerging and critical areas, fostering the exchange of ideas and promoting research collaborations to advance the state-of-the-art. This year's event will take place in Seoul, South Korea, and the program will feature a single track.},
location = {Seoul, Republic of Korea}
}

@article{10.1145/3706108,
author = {Kansal, Kajal and Wong, Yongkang and Kankanhalli, Mohan S.},
title = {Implications of Privacy Regulations on Video Surveillance Systems},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3706108},
doi = {10.1145/3706108},
abstract = {Advanced video surveillance systems (VSS), which collect information of every individual who passes through a surveilled area, have become ubiquitous due to its utility for security. However, such proactive monitoring threatens the individual's privacy due to the public's lack of control over personal data. Additionally, individuals or organizations may unethically misuse VSS for other purposes (e.g. individual profiling and unwarranted monitoring). To safeguard individual privacy, various governments have introduced mandatory information privacy regulations (e.g. GDPR, PDPA, and CCPA) to provide extensive guidelines for the purpose of achieving identity confidentiality. Currently, there is a gap between the information privacy regulations and VSS. This paper aims to bridge this gap through four contributions. First, this paper conceptualizes VSS as comprising various data stages based on the idea of data life cycle and studies the implications of existing regulations on VSS. Second, we conducted a survey in ASEAN and European regions to understand the public perception of data risks at each data stage. Third, we review existing privacy-enhancing technologies and its relation to each data stage. Finally, we discuss open research problems in order to realize privacy-aware VSS.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = nov,
keywords = {Video Surveillance, Privacy, Information Privacy Regulations}
}

@article{10.1145/3567675,
author = {Landauer, Max and Wurzenberger, Markus and Skopik, Florian and Hotwagner, Wolfgang and H\"{o}ld, Georg},
title = {AMiner: A Modular Log Data Analysis Pipeline for Anomaly-based Intrusion Detection},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
url = {https://doi.org/10.1145/3567675},
doi = {10.1145/3567675},
abstract = {Cyber attacks are omnipresent and their rapid detection is crucial for system security. Signature-based intrusion detection monitors systems for attack indicators and plays an important role in recognizing and preventing such attacks. Unfortunately, it is unable to detect new attack vectors and may be evaded by attack variants. As a solution, anomaly detection employs techniques from machine learning to detect suspicious log events without relying on predefined signatures. While visibility of attacks in network traffic is limited due to encryption of network packets, system log data is available in raw format and thus allows fine-granular analysis. However, system log processing is difficult as it involves different formats and heterogeneous events. To ease log-based anomaly detection, we present the AMiner, an open-source tool in the AECID toolbox that enables fast log parsing, analysis, and alerting. In this article, we outline the AMiner’s modular architecture and demonstrate its applicability in three use-cases.},
journal = {Digital Threats},
month = mar,
articleno = {12},
numpages = {16},
keywords = {intrusion detection systems, anomaly detection, Log data analysis}
}

@inproceedings{10.1145/3658644.3690369,
author = {Knauer, Jonathan and Rieger, Phillip and Fereidooni, Hossein and Sadeghi, Ahmad-Reza},
title = {Phantom: Untargeted Poisoning Attacks on Semi-Supervised Learning},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690369},
doi = {10.1145/3658644.3690369},
abstract = {Deep Neural Networks (DNNs) can handle increasingly complex tasks, albeit they require rapidly expanding training datasets. Collecting data from platforms with user-generated content, such as social networks, has significantly eased the acquisition of large datasets for training DNNs. Despite these advancements, the manual labeling process remains a substantial challenge in terms of both time and cost. In response, Semi-Supervised Learning (SSL) approaches have emerged, where only a small fraction of the dataset needs to be labeled, leaving the majority unlabeled. However, leveraging data from untrusted sources like social networks also creates new security risks, as potential attackers can easily inject manipulated samples. Previous research on the security of SSL primarily focused on injecting backdoors into trained models, while less attention was given to the more challenging untargeted poisoning attacks. In this paper, we introduce Phantom, the first untargeted poisoning attack in SSL that disrupts the training process by injecting a small number of manipulated images into the unlabeled dataset. Unlike existing attacks, our approach only requires adding few manipulated samples, such as posting images on social networks, without the need to control the victim. Phantom causes SSL algorithms to overlook the actual images' pixels and to rely only on maliciously crafted patterns that Phantom superimposed on the real images. We show Phantom's effectiveness for 6 different datasets and 3 real-world social-media platforms (Facebook, Instagram, Pinterest). Already small fractions of manipulated samples (e.g., 5\%) reduce the accuracy of the resulting model by 10\%, with higher percentages leading to a performance comparable to a naive classifier. Our findings demonstrate the threat of poisoning user-generated content platforms, rendering them unsuitable for SSL in specific tasks.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {615–629},
numpages = {15},
keywords = {deep neural network, poisoning, semi-supervised-learning},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@proceedings{10.1145/3655693,
title = {EICC '24: Proceedings of the 2024 European Interdisciplinary Cybersecurity Conference},
year = {2024},
isbn = {9798400716515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xanthi, Greece}
}

@inproceedings{10.1145/3544548.3580950,
author = {Roemmich, Kat and Schaub, Florian and Andalibi, Nazanin},
title = {Emotion AI at Work: Implications for Workplace Surveillance, Emotional Labor, and Emotional Privacy},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580950},
doi = {10.1145/3544548.3580950},
abstract = {Workplaces are increasingly adopting emotion AI, promising benefits to organizations. However, little is known about the perceptions and experiences of workers subject to emotion AI in the workplace. Our interview study with (n=15) US adult workers addresses this gap, finding that (1) participants viewed emotion AI as a deep privacy violation over the privacy of workers’ sensitive emotional information; (2) emotion AI may function to enforce workers’ compliance with emotional labor expectations, and that workers may engage in emotional labor as a mechanism to preserve privacy over their emotions; (3) workers may be exposed to a wide range of harms as a consequence of emotion AI in the workplace. Findings reveal the need to recognize and define an individual right to what we introduce as emotional privacy, as well as raise important research and policy questions on how to protect and preserve emotional privacy within and beyond the workplace.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {588},
numpages = {20},
keywords = {affective computing, artificial emotional intelligence, emotion AI, emotion recognition, emotional AI, emotional labor, future of work, passive sensing, privacy, surveillance, workplace},
location = {Hamburg, Germany},
series = {CHI '23}
}

@article{10.1145/3453930,
author = {Russinovich, Mark and Costa, Manuel and Fournet, C\'{e}dric and Chisnall, David and Delignat-Lavaud, Antoine and Clebsch, Sylvan and Vaswani, Kapil and Bhatia, Vikas},
title = {Toward confidential cloud computing},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {64},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/3453930},
doi = {10.1145/3453930},
abstract = {Extending hardware-enforced cryptographic protection to data while in use.},
journal = {Commun. ACM},
month = may,
pages = {54–61},
numpages = {8}
}

@article{10.1145/3454122.3456125,
author = {Russinovich, Mark and Costa, Manuel and Fournet, C\'{e}dric and Chisnall, David and Delignat-Lavaud, Antoine and Clebsch, Sylvan and Vaswani, Kapil and Bhatia, Vikas},
title = {Toward Confidential Cloud Computing: Extending hardware-enforced cryptographic protection to data while in use},
year = {2021},
issue_date = {January-February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1542-7730},
url = {https://doi.org/10.1145/3454122.3456125},
doi = {10.1145/3454122.3456125},
abstract = {Although largely driven by economies of scale, the development of the modern cloud also enables increased security. Large data centers provide aggregate availability, reliability, and security assurances. The operational cost of ensuring that operating systems, databases, and other services have secure configurations can be amortized among all tenants, allowing the cloud provider to employ experts who are responsible for security; this is often unfeasible for smaller businesses, where the role of systems administrator is often conflated with many others.},
journal = {Queue},
month = mar,
pages = {49–76},
numpages = {28}
}

